{
    "caption": "Table 2: Comparison with the state of the art on YCB-V. * indicates that the AUC is calculated with 11-points interpolation.",
    "table": [
        "<table id=\"S4.T2.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">&#13;\n<tr id=\"S4.T2.1.1\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T2.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Method</td>&#13;\n<td id=\"S4.T2.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">ADD(-S)</td>&#13;\n<td id=\"S4.T2.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">&#13;\n<span id=\"S4.T2.1.1.3.1\" class=\"ltx_text\"/> <span id=\"S4.T2.1.1.3.2\" class=\"ltx_text\">&#13;\n<span id=\"S4.T2.1.1.3.2.1\" class=\"ltx_tabular ltx_align_middle\">&#13;\n<span id=\"S4.T2.1.1.3.2.1.1\" class=\"ltx_tr\">&#13;\n<span id=\"S4.T2.1.1.3.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">AUC of</span></span>&#13;\n<span id=\"S4.T2.1.1.3.2.1.2\" class=\"ltx_tr\">&#13;\n<span id=\"S4.T2.1.1.3.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">ADD-S</span></span>&#13;\n</span></span><span id=\"S4.T2.1.1.3.3\" class=\"ltx_text\"/></td>&#13;\n<td id=\"S4.T2.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">&#13;\n<span id=\"S4.T2.1.1.4.1\" class=\"ltx_text\"/> <span id=\"S4.T2.1.1.4.2\" class=\"ltx_text\">&#13;\n<span id=\"S4.T2.1.1.4.2.1\" class=\"ltx_tabular ltx_align_middle\">&#13;\n<span id=\"S4.T2.1.1.4.2.1.1\" class=\"ltx_tr\">&#13;\n<span id=\"S4.T2.1.1.4.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">AUC of</span></span>&#13;\n<span id=\"S4.T2.1.1.4.2.1.2\" class=\"ltx_tr\">&#13;\n<span id=\"S4.T2.1.1.4.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">ADD(-S)</span></span>&#13;\n</span></span><span id=\"S4.T2.1.1.4.3\" class=\"ltx_text\"/></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T2.1.2\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T2.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">RePose&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib25\" title=\"\" class=\"ltx_ref\">25</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S4.T2.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">62.1</td>&#13;\n<td id=\"S4.T2.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">88.5</td>&#13;\n<td id=\"S4.T2.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">82.0</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T2.1.3\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T2.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_r\">RNNPose&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib50\" title=\"\" class=\"ltx_ref\">50</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S4.T2.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">66.4</td>&#13;\n<td id=\"S4.T2.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n<td id=\"S4.T2.1.3.4\" class=\"ltx_td ltx_align_center\">83.1</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T2.1.4\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T2.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_r\">SO-Pose&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib12\" title=\"\" class=\"ltx_ref\">12</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S4.T2.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">56.8</td>&#13;\n<td id=\"S4.T2.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">*90.9</td>&#13;\n<td id=\"S4.T2.1.4.4\" class=\"ltx_td ltx_align_center\">*83.9</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T2.1.5\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T2.1.5.1\" class=\"ltx_td ltx_align_center ltx_border_r\">DProST&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib36\" title=\"\" class=\"ltx_ref\">36</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S4.T2.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\">65.1</td>&#13;\n<td id=\"S4.T2.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n<td id=\"S4.T2.1.5.4\" class=\"ltx_td ltx_align_center\">77.4</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T2.1.6\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T2.1.6.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">GDR-Net&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib46\" title=\"\" class=\"ltx_ref\">46</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S4.T2.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">60.1</td>&#13;\n<td id=\"S4.T2.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">*91.6</td>&#13;\n<td id=\"S4.T2.1.6.4\" class=\"ltx_td ltx_align_center ltx_border_t\">*84.4</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T2.1.7\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T2.1.7.1\" class=\"ltx_td ltx_align_center ltx_border_r\">ZebraPose&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib43\" title=\"\" class=\"ltx_ref\">43</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S4.T2.1.7.2\" class=\"ltx_td ltx_align_center ltx_border_r\">80.5</td>&#13;\n<td id=\"S4.T2.1.7.3\" class=\"ltx_td ltx_align_center ltx_border_r\">90.1</td>&#13;\n<td id=\"S4.T2.1.7.4\" class=\"ltx_td ltx_align_center\">85.3</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T2.1.8\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T2.1.8.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">GDR-Net-LC</td>&#13;\n<td id=\"S4.T2.1.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">70.6</td>&#13;\n<td id=\"S4.T2.1.8.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">89.8, *94.1</td>&#13;\n<td id=\"S4.T2.1.8.4\" class=\"ltx_td ltx_align_center ltx_border_t\">84.0, *88.8</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T2.1.9\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T2.1.9.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">ZebraPose-LC</td>&#13;\n<td id=\"S4.T2.1.9.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S4.T2.1.9.2.1\" class=\"ltx_text ltx_font_bold\">82.4</span></td>&#13;\n<td id=\"S4.T2.1.9.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">&#13;\n<span id=\"S4.T2.1.9.3.1\" class=\"ltx_text ltx_font_bold\">90.8</span>, <span id=\"S4.T2.1.9.3.2\" class=\"ltx_text ltx_font_bold\">*95.0</span>&#13;\n</td>&#13;\n<td id=\"S4.T2.1.9.4\" class=\"ltx_td ltx_align_center ltx_border_b\">&#13;\n<span id=\"S4.T2.1.9.4.1\" class=\"ltx_text ltx_font_bold\">86.1</span>, <span id=\"S4.T2.1.9.4.2\" class=\"ltx_text ltx_font_bold\">*90.8</span>&#13;\n</td>&#13;\n</tr>&#13;\n</table>&#13;\n\n"
    ],
    "footnotes": [
        "[25] [25]\r\n\r\nShun Iwase, Xingyu Liu, Rawal Khirodkar, Rio Yokota, and Kris M. Kitani.\r\n\r\n\r\nRepose: Fast 6d object pose refinement via deep texture rendering.\r\n\r\n\r\nIn Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 3303–3312, October 2021.",
        "[50] [50]\r\n\r\nYan Xu, Kwan-Yee Lin, Guofeng Zhang, Xiaogang Wang, and Hongsheng Li.\r\n\r\n\r\nRnnpose: Recurrent 6-dof object pose refinement with robust correspondence field estimation and pose optimization.\r\n\r\n\r\nIn Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 14880–14890, June 2022.",
        "[12] [12]\r\n\r\nYan Di, Fabian Manhardt, Gu Wang, Xiangyang Ji, Nassir Navab, and Federico Tombari.\r\n\r\n\r\nSo-pose: Exploiting self-occlusion for direct 6d pose estimation.\r\n\r\n\r\nIn Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 12396–12405, October 2021.",
        "[36] [36]\r\n\r\nJaewoo Park and Nam Ik Cho.\r\n\r\n\r\nDprost: Dynamic projective spatial transformer network for 6d pose estimation.\r\n\r\n\r\nIn Shai Avidan, Gabriel Brostow, Moustapha Cissé, Giovanni Maria Farinella, and Tal Hassner, editors, Computer Vision – ECCV 2022, pages 363–379, Cham, 2022. Springer Nature Switzerland.",
        "[46] [46]\r\n\r\nGu Wang, Fabian Manhardt, Federico Tombari, and Xiangyang Ji.\r\n\r\n\r\nGdr-net: Geometry-guided direct regression network for monocular 6d object pose estimation.\r\n\r\n\r\nIn Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 16611–16621, June 2021.",
        "[43] [43]\r\n\r\nYongzhi Su, Mahdi Saleh, Torben Fetzer, Jason Rambach, Nassir Navab, Benjamin Busam, Didier Stricker, and Federico Tombari.\r\n\r\n\r\nZebrapose: Coarse to fine surface encoding for 6dof object pose estimation.\r\n\r\n\r\nIn Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 6738–6748, June 2022."
    ],
    "references": [
        "Results on YCB-V. As summarized in Tab. 2, applying the LC loss on GDR-Net produces results second only to ZebraPose. Furthermore, we achieve state-of-the-art performance when the LC loss is applied to ZebraPose. We implement a symmetry-aware training scheme which selects the ground-truth pose on the fly based on the average distance between the predicted 3D coordinates at randomly selected 2D locations and possible 3D coordinates at the same locations under the symmetric ground-truth pose. This scheme is only applied to the GDR-Net-based experiments on YCB-V, including the baseline and the model with our LC loss for fair comparison."
    ]
}