{
    "caption": "(b) \r\nMulti-hypothesis aggregation.\r\n\r\n",
    "table": [
        "<table id=\"S4.T3.sf2.1.1.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">&#13;\n<tr id=\"S4.T3.sf2.1.1.1.1\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.sf2.1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.1.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">Level</span></td>&#13;\n<td id=\"S4.T3.sf2.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.1.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">Method</span></td>&#13;\n<td id=\"S4.T3.sf2.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:-1.2pt 2.0pt;\">&#13;\n<span id=\"S4.T3.sf2.1.1.1.1.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">MPJPE</span><math id=\"S4.T3.sf2.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\downarrow\" display=\"inline\"><semantics id=\"S4.T3.sf2.1.1.1.1.1.m1.1a\"><mo mathsize=\"80%\" stretchy=\"false\" id=\"S4.T3.sf2.1.1.1.1.1.m1.1.1\" xref=\"S4.T3.sf2.1.1.1.1.1.m1.1.1.cmml\">&#8595;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.sf2.1.1.1.1.1.m1.1b\"><ci id=\"S4.T3.sf2.1.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T3.sf2.1.1.1.1.1.m1.1.1\">&#8595;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.sf2.1.1.1.1.1.m1.1c\">\\downarrow</annotation></semantics></math>&#13;\n</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.sf2.1.1.1.2\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.sf2.1.1.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.2.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">pose</span></td>&#13;\n<td id=\"S4.T3.sf2.1.1.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.2.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">average</span></td>&#13;\n<td id=\"S4.T3.sf2.1.1.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.2.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">39.9</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.sf2.1.1.1.3\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.sf2.1.1.1.3.1\" class=\"ltx_td ltx_align_center\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.3.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">pose</span></td>&#13;\n<td id=\"S4.T3.sf2.1.1.1.3.2\" class=\"ltx_td ltx_align_center\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.3.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">MLPs</span></td>&#13;\n<td id=\"S4.T3.sf2.1.1.1.3.3\" class=\"ltx_td ltx_align_center\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.3.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">42.5</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.sf2.1.1.1.4\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.sf2.1.1.1.4.1\" class=\"ltx_td ltx_align_center\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.4.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">joint</span></td>&#13;\n<td id=\"S4.T3.sf2.1.1.1.4.2\" class=\"ltx_td ltx_align_center\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.4.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">MLPs</span></td>&#13;\n<td id=\"S4.T3.sf2.1.1.1.4.3\" class=\"ltx_td ltx_align_center\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.4.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">41.6</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.sf2.1.1.1.5\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.sf2.1.1.1.5.1\" class=\"ltx_td ltx_align_center\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.5.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">pose</span></td>&#13;\n<td id=\"S4.T3.sf2.1.1.1.5.2\" class=\"ltx_td ltx_align_center\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.5.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">reproj.</span></td>&#13;\n<td id=\"S4.T3.sf2.1.1.1.5.3\" class=\"ltx_td ltx_align_center\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.5.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">39.7</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.sf2.1.1.1.6\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.sf2.1.1.1.6.1\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.6.1.1\" class=\"ltx_text\" style=\"font-size:80%;\">joint</span></td>&#13;\n<td id=\"S4.T3.sf2.1.1.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.6.2.1\" class=\"ltx_text\" style=\"font-size:80%;\">reproj.</span></td>&#13;\n<td id=\"S4.T3.sf2.1.1.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_b\" style=\"padding:-1.2pt 2.0pt;\"><span id=\"S4.T3.sf2.1.1.1.6.3.1\" class=\"ltx_text\" style=\"font-size:80%;\">39.5</span></td>&#13;\n</tr>&#13;\n</table>&#13;\n\n"
    ],
    "footnotes": [],
    "references": [
        "We implement two alternatives: predicting the noise ϵtsubscriptitalic-ϵ𝑡\\epsilon_{t} at each timestep of the reverse process or predicting the original 3D data 𝒚0subscript𝒚0\\bm{y}_{0}. As shown in Table 5a, the latter achieves better results.",
        "Note that the difference between our work and other concurrent diffusion-based methods [22, 18, 14] mainly lies in the regression target. The regression target of our model is the original 3D data 𝒚0subscript𝒚0\\bm{y}_{0}, while theirs is the noise ϵtsubscriptitalic-ϵ𝑡\\epsilon_{t} at each timestep. Table 5a shows our method outperforms theirs. Further experiments (Table 6) reveal that predicting 𝒚0subscript𝒚0\\bm{y}_{0} yields good performance even in early iterations, while predicting ϵtsubscriptitalic-ϵ𝑡\\epsilon_{t} does not. This is because in early iterations, when the input 𝒚tsubscript𝒚𝑡\\bm{y}_{t} is extremely noisy, it is more effective to predict the original signal 𝒚0subscript𝒚0\\bm{y}_{0} directly than to obtain 𝒚0subscript𝒚0\\bm{y}_{0} by predicting the noise ϵtsubscriptitalic-ϵ𝑡\\epsilon_{t} and then subtracting it from 𝒚tsubscript𝒚𝑡\\bm{y}_{t}. This property is valuable for real-time processing. For example, when K𝐾K is fixed and computational resources are inadequate, the algorithm is required to produce predictions after the first iteration. Our method of predicting 𝒚0subscript𝒚0\\bm{y}_{0} still achieves satisfactory results, while theirs of predicting ϵtsubscriptitalic-ϵ𝑡\\epsilon_{t} does not.",
        "We add the timestep embedding to the network in a similar way as the positional embedding [58]. Table 5b shows that adding it to the first layer of the network performs the same as all layers, hence the former is chosen for simplicity. Experimental results demonstrate that timestep embedding is crucial to the denoising process.",
        "Three data augmentation approaches are compared in Table 5c, including 1) no augmentation; 2) flipping-once, which flips the input, conducts denoising for K𝐾K times, and flips the prediction again. The flipped prediction is then averaged with the unflipped prediction in the original branch to yield the final output; 3) diffusion-flipping, which applies the flip-denoise-flip process to each timestep (K𝐾K times). The detailed architectures of these three approaches are shown in Fig. 7. Our diffusion-flipping achieves the best results because it averages the 3D poses of the original and flipped branches at each timestep, preventing the accumulation of errors. Other concurrent diffusion-based methods [22, 18, 14] don’t use any augmentation or use the flipping-once method. Therefore, our model is more effective than theirs.",
        "As shown in Table 5d, we evaluate multiple fusion methods (concatenation, addition, and cross attention [58]) in two fusion types (input fusion and embedding fusion). For embedding fusion, two additional spatio-temporal Transformer layers are used to extract 2D features, after which these features are fused into the denoiser. The best fusion approach is concatenating noisy 3D poses and 2D conditions on the input side, which provides a fast and effective way to modify existing 3D pose estimators to fit the diffusion framework.",
        "Table 5e indicates that the best performance can be achieved by setting an appropriate maximum number of timesteps. When T𝑇T is too small, we cannot diffuse the ground truth 3D poses to a Gaussian distribution during training, so the denoiser has trouble recovering a clean pose from Gaussian noise during inference. When T𝑇T is too large, excessive samples become pure noise after diffusion. Then, the training process of the denoiser is affected and the denoiser cannot generalize well to 3D poses with varying levels of noise (i.e., 3D poses at different timesteps) during inference."
    ]
}