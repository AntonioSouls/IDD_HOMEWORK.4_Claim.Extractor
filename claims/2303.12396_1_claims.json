{
    "caption": "Table 1: Detection comparison on different 6D object datasets.\r\nOur method achieves much better accuracy than the baseline methods on these BOP datasets, demonstrating the effectiveness of our approach at detecting rigid objects in cluttered 6D pose estimation scenarios.\r\n",
    "table": [
        "<table id=\"S3.T1.2\" class=\"ltx_tabular ltx_centering ltx_align_middle\">&#13;\n<tr id=\"S3.T1.2.1\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T1.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_tt\">Method</td>&#13;\n<td id=\"S3.T1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">LM-O</td>&#13;\n<td id=\"S3.T1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">T-LESS</td>&#13;\n<td id=\"S3.T1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">TUD-L</td>&#13;\n<td id=\"S3.T1.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_tt\">IC-BIN</td>&#13;\n<td id=\"S3.T1.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_tt\">ITODD</td>&#13;\n<td id=\"S3.T1.2.1.7\" class=\"ltx_td ltx_align_center ltx_border_tt\">HB</td>&#13;\n<td id=\"S3.T1.2.1.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">YCB</td>&#13;\n<td id=\"S3.T1.2.1.9\" class=\"ltx_td ltx_align_center ltx_border_tt\">Avg.</td>&#13;\n</tr>&#13;\n<tr id=\"S3.T1.2.2\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T1.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_r ltx_border_t\"><span id=\"S3.T1.2.2.1.1\" class=\"ltx_text ltx_font_bold\">Ours</span></td>&#13;\n<td id=\"S3.T1.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T1.2.2.2.1\" class=\"ltx_text ltx_font_bold\">67.5</span></td>&#13;\n<td id=\"S3.T1.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T1.2.2.3.1\" class=\"ltx_text ltx_font_bold\">79.8</span></td>&#13;\n<td id=\"S3.T1.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T1.2.2.4.1\" class=\"ltx_text ltx_font_bold\">86.6</span></td>&#13;\n<td id=\"S3.T1.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T1.2.2.5.1\" class=\"ltx_text ltx_font_bold\">63.8</span></td>&#13;\n<td id=\"S3.T1.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T1.2.2.6.1\" class=\"ltx_text ltx_font_bold\">48.6</span></td>&#13;\n<td id=\"S3.T1.2.2.7\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T1.2.2.7.1\" class=\"ltx_text ltx_font_bold\">73.5</span></td>&#13;\n<td id=\"S3.T1.2.2.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S3.T1.2.2.8.1\" class=\"ltx_text ltx_font_bold\">85.0</span></td>&#13;\n<td id=\"S3.T1.2.2.9\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T1.2.2.9.1\" class=\"ltx_text ltx_font_bold\">72.1</span></td>&#13;\n</tr>&#13;\n<tr id=\"S3.T1.2.3\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T1.2.3.1\" class=\"ltx_td ltx_align_left ltx_border_r\">FCOSv2&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib44\" title=\"\" class=\"ltx_ref\">44</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S3.T1.2.3.2\" class=\"ltx_td ltx_align_center\">57.0</td>&#13;\n<td id=\"S3.T1.2.3.3\" class=\"ltx_td ltx_align_center\">75.0</td>&#13;\n<td id=\"S3.T1.2.3.4\" class=\"ltx_td ltx_align_center\">86.0</td>&#13;\n<td id=\"S3.T1.2.3.5\" class=\"ltx_td ltx_align_center\">27.2</td>&#13;\n<td id=\"S3.T1.2.3.6\" class=\"ltx_td ltx_align_center\">30.4</td>&#13;\n<td id=\"S3.T1.2.3.7\" class=\"ltx_td ltx_align_center\">60.4</td>&#13;\n<td id=\"S3.T1.2.3.8\" class=\"ltx_td ltx_align_center ltx_border_r\">80.0</td>&#13;\n<td id=\"S3.T1.2.3.9\" class=\"ltx_td ltx_align_center\">66.7</td>&#13;\n</tr>&#13;\n<tr id=\"S3.T1.2.4\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T1.2.4.1\" class=\"ltx_td ltx_align_left ltx_border_bb ltx_border_r\">Mask R-CNN&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">10</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S3.T1.2.4.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">56.6</td>&#13;\n<td id=\"S3.T1.2.4.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">69.3</td>&#13;\n<td id=\"S3.T1.2.4.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">82.6</td>&#13;\n<td id=\"S3.T1.2.4.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">40.1</td>&#13;\n<td id=\"S3.T1.2.4.6\" class=\"ltx_td ltx_align_center ltx_border_bb\">36.5</td>&#13;\n<td id=\"S3.T1.2.4.7\" class=\"ltx_td ltx_align_center ltx_border_bb\">63.5</td>&#13;\n<td id=\"S3.T1.2.4.8\" class=\"ltx_td ltx_align_center ltx_border_bb ltx_border_r\">74.5</td>&#13;\n<td id=\"S3.T1.2.4.9\" class=\"ltx_td ltx_align_center ltx_border_bb\">60.5</td>&#13;\n</tr>&#13;\n</table>&#13;\n\n"
    ],
    "footnotes": [
        "[44] [44]\r\n\r\nZhi Tian, Chunhua Shen, Hao Chen, and Tong He.\r\n\r\n\r\nFCOS: A Simple and Strong Anchor-Free Object Detector.\r\n\r\n\r\nIEEE Transactions on Pattern Analysis and Machine Intelligence,\r\n44(4):1922–1933, 2020.",
        "[10] [10]\r\n\r\nKaiming He, Georgia Gkioxari, Piotr Dollár, and Ross B. Girshick.\r\n\r\n\r\nMask R-CNN.\r\n\r\n\r\nIn International Conference on Computer Vision, 2017."
    ],
    "references": [
        "Comparison with the baselines.\r\nWe compare our method with the baseline single-stage method FCOSv2 [44] and a typical two-stage method, Mask R-CNN [10].\r\nAs shown in Table 1, our method outperforms them by a large margin on all datasets from the BOP benchmarks, demonstrating the effectiveness of our approach at detecting rigid objects in cluttered 6D pose estimation scenarios.",
        "Additional quantitative results.\r\nWe show the detailed object pose results using different metrics on LM-O, T-LESS, TUD-L, IC-BIN, ITODD, HB, and YCB in Table 8, 9, 10, 11, 12, 13, and 14, respectively.\r\nOur method combined with PFA-Pose [15] outperforms the state of the art in most experimental settings."
    ]
}