{
    "caption": "Table 6: \r\nEffect on different pose regression networks.\r\nOur detection method consistently improves the results of different pose regression frameworks, including WDR [19] and CDPNv2 [26]. Here we denote Mask R-CNN [10] as “RCNN’.\r\n",
    "table": [
        "<table id=\"S4.T6.2\" class=\"ltx_tabular ltx_centering ltx_align_middle\">&#13;\n<tr id=\"S4.T6.2.1\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T6.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_tt\">Method</td>&#13;\n<td id=\"S4.T6.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_tt\">Avg.</td>&#13;\n<td id=\"S4.T6.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_tt\">MSPD</td>&#13;\n<td id=\"S4.T6.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_tt\">MSSD</td>&#13;\n<td id=\"S4.T6.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_tt\">VSD</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T6.2.2\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T6.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\">WDR + <span id=\"S4.T6.2.2.1.1\" class=\"ltx_text ltx_font_bold\">Ours</span>&#13;\n</td>&#13;\n<td id=\"S4.T6.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T6.2.2.2.1\" class=\"ltx_text ltx_font_bold\">0.605</span></td>&#13;\n<td id=\"S4.T6.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T6.2.2.3.1\" class=\"ltx_text ltx_font_bold\">0.694</span></td>&#13;\n<td id=\"S4.T6.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T6.2.2.4.1\" class=\"ltx_text ltx_font_bold\">0.598</span></td>&#13;\n<td id=\"S4.T6.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T6.2.2.5.1\" class=\"ltx_text ltx_font_bold\">0.522</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T6.2.3\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T6.2.3.1\" class=\"ltx_td ltx_align_left\">WDR + RCNN</td>&#13;\n<td id=\"S4.T6.2.3.2\" class=\"ltx_td ltx_align_center\">0.587</td>&#13;\n<td id=\"S4.T6.2.3.3\" class=\"ltx_td ltx_align_center\">0.673</td>&#13;\n<td id=\"S4.T6.2.3.4\" class=\"ltx_td ltx_align_center\">0.580</td>&#13;\n<td id=\"S4.T6.2.3.5\" class=\"ltx_td ltx_align_center\">0.508</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T6.2.4\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T6.2.4.1\" class=\"ltx_td ltx_align_left\">WDR + FCOSv2</td>&#13;\n<td id=\"S4.T6.2.4.2\" class=\"ltx_td ltx_align_center\">0.585</td>&#13;\n<td id=\"S4.T6.2.4.3\" class=\"ltx_td ltx_align_center\">0.671</td>&#13;\n<td id=\"S4.T6.2.4.4\" class=\"ltx_td ltx_align_center\">0.578</td>&#13;\n<td id=\"S4.T6.2.4.5\" class=\"ltx_td ltx_align_center\">0.506</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T6.2.5\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T6.2.5.1\" class=\"ltx_td ltx_align_left\">CDPNv2 + <span id=\"S4.T6.2.5.1.1\" class=\"ltx_text ltx_font_bold\">Ours</span>&#13;\n</td>&#13;\n<td id=\"S4.T6.2.5.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T6.2.5.2.1\" class=\"ltx_text ltx_font_bold\">0.412</span></td>&#13;\n<td id=\"S4.T6.2.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T6.2.5.3.1\" class=\"ltx_text ltx_font_bold\">0.534</span></td>&#13;\n<td id=\"S4.T6.2.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T6.2.5.4.1\" class=\"ltx_text ltx_font_bold\">0.428</span></td>&#13;\n<td id=\"S4.T6.2.5.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T6.2.5.5.1\" class=\"ltx_text ltx_font_bold\">0.275</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T6.2.6\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T6.2.6.1\" class=\"ltx_td ltx_align_left\">CDPNv2 + FCOSv2</td>&#13;\n<td id=\"S4.T6.2.6.2\" class=\"ltx_td ltx_align_center\">0.402</td>&#13;\n<td id=\"S4.T6.2.6.3\" class=\"ltx_td ltx_align_center\">0.523</td>&#13;\n<td id=\"S4.T6.2.6.4\" class=\"ltx_td ltx_align_center\">0.416</td>&#13;\n<td id=\"S4.T6.2.6.5\" class=\"ltx_td ltx_align_center\">0.268</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T6.2.7\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T6.2.7.1\" class=\"ltx_td ltx_align_left ltx_border_bb\">CDPNv2 + RCNN</td>&#13;\n<td id=\"S4.T6.2.7.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.388</td>&#13;\n<td id=\"S4.T6.2.7.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.506</td>&#13;\n<td id=\"S4.T6.2.7.4\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.401</td>&#13;\n<td id=\"S4.T6.2.7.5\" class=\"ltx_td ltx_align_center ltx_border_bb\">0.258</td>&#13;\n</tr>&#13;\n</table>&#13;\n\n"
    ],
    "footnotes": [
        "[19] [19]\r\n\r\nYinlin Hu, Sebastien Speierer, Wenzel Jakob, Pascal Fua, and Mathieu Salzmann.\r\n\r\n\r\nWide-Depth-Range 6D Object Pose Estimation in Space.\r\n\r\n\r\nIn Conference on Computer Vision and Pattern Recognition, 2021.",
        "[26] [26]\r\n\r\nZhigang Li, Gu Wang, and Xiangyang Ji.\r\n\r\n\r\nCDPN: Coordinates-Based Disentangled Pose Network for Real-Time\r\nRGB-Based 6-DoF Object Pose Estimation.\r\n\r\n\r\nIn International Conference on Computer Vision, 2019.",
        "[10] [10]\r\n\r\nKaiming He, Georgia Gkioxari, Piotr Dollár, and Ross B. Girshick.\r\n\r\n\r\nMask R-CNN.\r\n\r\n\r\nIn International Conference on Computer Vision, 2017."
    ],
    "references": [
        "Evaluation with different pose regression networks.\r\nIn principle, our detection method can be used with most pose regression frameworks as a first component to extract the object’s bounding box before pose regression.\r\nTo demonstrate its generalization ability, we test our detection method on YCB with two other typical pose regression networks, WDR-Pose [19] and CDPNv2 [26].\r\nTable 6 provides the results, evidencing that our detection method consistently improves the pose results."
    ]
}