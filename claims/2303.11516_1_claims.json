{
    "caption": "Table 1: Comparison with the state of the art on LM-O. The “LC” postfix indicates the LC loss is applied.",
    "table": [
        "<table id=\"S4.T1.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">&#13;\n<tr id=\"S4.T1.1.1\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Method</td>&#13;\n<td id=\"S4.T1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Training Data</td>&#13;\n<td id=\"S4.T1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">ADD(-S)</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T1.1.2\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T1.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">RePOSE&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib25\" title=\"\" class=\"ltx_ref\">25</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S4.T1.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">real+syn</td>&#13;\n<td id=\"S4.T1.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">51.6</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T1.1.3\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T1.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_r\">RNNPose&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib50\" title=\"\" class=\"ltx_ref\">50</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S4.T1.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">real+syn</td>&#13;\n<td id=\"S4.T1.1.3.3\" class=\"ltx_td ltx_align_center\">60.65</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T1.1.4\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T1.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_r\">SO-Pose&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib12\" title=\"\" class=\"ltx_ref\">12</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S4.T1.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">real+pbr</td>&#13;\n<td id=\"S4.T1.1.4.3\" class=\"ltx_td ltx_align_center\">62.3</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T1.1.5\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T1.1.5.1\" class=\"ltx_td ltx_align_center ltx_border_r\">DProST&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib36\" title=\"\" class=\"ltx_ref\">36</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S4.T1.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\">real+pbr</td>&#13;\n<td id=\"S4.T1.1.5.3\" class=\"ltx_td ltx_align_center\">62.6</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T1.1.6\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T1.1.6.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">GDR-Net&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib46\" title=\"\" class=\"ltx_ref\">46</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S4.T1.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">real+pbr</td>&#13;\n<td id=\"S4.T1.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_t\">62.2</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T1.1.7\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T1.1.7.1\" class=\"ltx_td ltx_align_center ltx_border_r\">ZebraPose&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib43\" title=\"\" class=\"ltx_ref\">43</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S4.T1.1.7.2\" class=\"ltx_td ltx_align_center ltx_border_r\">real+pbr</td>&#13;\n<td id=\"S4.T1.1.7.3\" class=\"ltx_td ltx_align_center\">76.9</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T1.1.8\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T1.1.8.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">GDR-Net-LC</td>&#13;\n<td id=\"S4.T1.1.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">real+pbr</td>&#13;\n<td id=\"S4.T1.1.8.3\" class=\"ltx_td ltx_align_center ltx_border_t\">66.48</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T1.1.9\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T1.1.9.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">ZebraPose-LC</td>&#13;\n<td id=\"S4.T1.1.9.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">real+pbr</td>&#13;\n<td id=\"S4.T1.1.9.3\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T1.1.9.3.1\" class=\"ltx_text ltx_font_bold\">78.06</span></td>&#13;\n</tr>&#13;\n</table>&#13;\n\n"
    ],
    "footnotes": [
        "[25] [25]\r\n\r\nShun Iwase, Xingyu Liu, Rawal Khirodkar, Rio Yokota, and Kris M. Kitani.\r\n\r\n\r\nRepose: Fast 6d object pose refinement via deep texture rendering.\r\n\r\n\r\nIn Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 3303–3312, October 2021.",
        "[50] [50]\r\n\r\nYan Xu, Kwan-Yee Lin, Guofeng Zhang, Xiaogang Wang, and Hongsheng Li.\r\n\r\n\r\nRnnpose: Recurrent 6-dof object pose refinement with robust correspondence field estimation and pose optimization.\r\n\r\n\r\nIn Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 14880–14890, June 2022.",
        "[12] [12]\r\n\r\nYan Di, Fabian Manhardt, Gu Wang, Xiangyang Ji, Nassir Navab, and Federico Tombari.\r\n\r\n\r\nSo-pose: Exploiting self-occlusion for direct 6d pose estimation.\r\n\r\n\r\nIn Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 12396–12405, October 2021.",
        "[36] [36]\r\n\r\nJaewoo Park and Nam Ik Cho.\r\n\r\n\r\nDprost: Dynamic projective spatial transformer network for 6d pose estimation.\r\n\r\n\r\nIn Shai Avidan, Gabriel Brostow, Moustapha Cissé, Giovanni Maria Farinella, and Tal Hassner, editors, Computer Vision – ECCV 2022, pages 363–379, Cham, 2022. Springer Nature Switzerland.",
        "[46] [46]\r\n\r\nGu Wang, Fabian Manhardt, Federico Tombari, and Xiangyang Ji.\r\n\r\n\r\nGdr-net: Geometry-guided direct regression network for monocular 6d object pose estimation.\r\n\r\n\r\nIn Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 16611–16621, June 2021.",
        "[43] [43]\r\n\r\nYongzhi Su, Mahdi Saleh, Torben Fetzer, Jason Rambach, Nassir Navab, Benjamin Busam, Didier Stricker, and Federico Tombari.\r\n\r\n\r\nZebrapose: Coarse to fine surface encoding for 6dof object pose estimation.\r\n\r\n\r\nIn Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 6738–6748, June 2022."
    ],
    "references": [
        "Results on LM-O. We report the ADD(-S) score on LM-O in Tab. 1.\r\nApplying the LC loss on GDR-Net surpasses most methods, and we achieve state-of-the-art performance when applying it to ZebraPose.",
        "For the YCB-V dataset, we provide the detailed comparison of ADD(-S) scores (Tab. 8) and AUC scores (Tab. 10) between the baseline methods and the versions where the LC loss is applied."
    ]
}