{
    "caption": "Table 3: Comparison between PnP layers on LM-O.",
    "table": [
        "<table id=\"S4.T3.3.3\" class=\"ltx_tabular ltx_centering ltx_align_middle\">&#13;\n<tr id=\"S4.T3.3.3.4\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.3.3.4.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Method</td>&#13;\n<td id=\"S4.T3.3.3.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">ADD(-S)</td>&#13;\n<td id=\"S4.T3.3.3.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Correctness</td>&#13;\n<td id=\"S4.T3.3.3.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">Runtime</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.1.1.1\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">BPnP&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib6\" title=\"\" class=\"ltx_ref\">6</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S4.T3.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">64.1</td>&#13;\n<td id=\"S4.T3.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">53.9</td>&#13;\n<td id=\"S4.T3.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\">&#13;\n<math id=\"S4.T3.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\sim\" display=\"inline\"><semantics id=\"S4.T3.1.1.1.1.m1.1a\"><mo id=\"S4.T3.1.1.1.1.m1.1.1\" xref=\"S4.T3.1.1.1.1.m1.1.1.cmml\">&#8764;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.1.1.1.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.T3.1.1.1.1.m1.1.1.cmml\" xref=\"S4.T3.1.1.1.1.m1.1.1\">similar-to</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.1.1.1.1.m1.1c\">\\sim</annotation></semantics></math> 30 ms</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.2.2.2\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">EPro-PnP&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib7\" title=\"\" class=\"ltx_ref\">7</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S4.T3.2.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\">64.5</td>&#13;\n<td id=\"S4.T3.2.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\">59.3</td>&#13;\n<td id=\"S4.T3.2.2.2.1\" class=\"ltx_td ltx_align_center\">&#13;\n<math id=\"S4.T3.2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\sim\" display=\"inline\"><semantics id=\"S4.T3.2.2.2.1.m1.1a\"><mo id=\"S4.T3.2.2.2.1.m1.1.1\" xref=\"S4.T3.2.2.2.1.m1.1.1.cmml\">&#8764;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.2.2.2.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.T3.2.2.2.1.m1.1.1.cmml\" xref=\"S4.T3.2.2.2.1.m1.1.1\">similar-to</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.2.2.2.1.m1.1c\">\\sim</annotation></semantics></math> 80 ms</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.3.3.3\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.3.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">Ours</td>&#13;\n<td id=\"S4.T3.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S4.T3.3.3.3.3.1\" class=\"ltx_text ltx_font_bold\">66.5</span></td>&#13;\n<td id=\"S4.T3.3.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S4.T3.3.3.3.4.1\" class=\"ltx_text ltx_font_bold\">99.9</span></td>&#13;\n<td id=\"S4.T3.3.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_b\">&#13;\n<math id=\"S4.T3.3.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\sim\" display=\"inline\"><semantics id=\"S4.T3.3.3.3.1.m1.1a\"><mo id=\"S4.T3.3.3.3.1.m1.1.1\" xref=\"S4.T3.3.3.3.1.m1.1.1.cmml\">&#8764;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S4.T3.3.3.3.1.m1.1b\"><csymbol cd=\"latexml\" id=\"S4.T3.3.3.3.1.m1.1.1.cmml\" xref=\"S4.T3.3.3.3.1.m1.1.1\">similar-to</csymbol></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.T3.3.3.3.1.m1.1c\">\\sim</annotation></semantics></math> <span id=\"S4.T3.3.3.3.1.1\" class=\"ltx_text ltx_font_bold\">15</span> ms</td>&#13;\n</tr>&#13;\n</table>&#13;\n\n"
    ],
    "footnotes": [
        "[6] [6]\r\n\r\nBo Chen, Alvaro Parra, Jiewei Cao, Nan Li, and Tat-Jun Chin.\r\n\r\n\r\nEnd-to-end learnable geometric vision by backpropagating pnp optimization.\r\n\r\n\r\nIn Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), June 2020.",
        "[7] [7]\r\n\r\nHansheng Chen, Pichao Wang, Fan Wang, Wei Tian, Lu Xiong, and Hao Li.\r\n\r\n\r\nEpro-pnp: Generalized end-to-end probabilistic perspective-n-points for monocular object pose estimation.\r\n\r\n\r\nIn Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 2781–2790, June 2022."
    ],
    "references": [
        "Comparison with Differentiable PnP layers. As summarized in Tab. 3, we carry out experiments on LM-O with the GDR-Net baseline, and compare the methods based on several metrics\r\nincluding the ADD(-S) score, the gradient correctness and the runtime per training step,\r\nthe correctness and runtime are evaluated at the end of training. Note that BPnP [6] does not fully constrain the weights, thus we remove the scale branch as stated in Sec. 4.1. Our method yields the best ADD(-S) score on LM-O. More importantly, it generates a much larger percentage of correct gradients. A 3D point is considered to have correct gradients if moving in the negative gradient direction leads to a smaller 2D reprojection error. A pose loss yielding a higher gradient correctness provides more consistent supervision signals.\r\nThe consistency is reflected by the dilated weight and coordinate maps shown in Fig. 5, in particular by looking at pixels outside of but close to the actual object region.\r\nSuch pixels receive supervision only from the pose loss and thus indicate the differences between the different pose losses.\r\nHigher correctness helps the network to predict correct correspondences for such pixels.\r\nThis virtually expands the target object size in 3D object space and in 2D image space, which facilitates better pose estimates. The LC loss yields 99.9% gradient correctness, generating the most dilated maps. By contrast, the other losses have weaker consistency and thus tend to predict less accurate correspondences in these regions. Finally, as shown in Tab. 3, our LC loss yields the fastest runtime, evaluated on an NVIDIA A100 GPU with a batch size of 32. This is due to our linearization of the PnP solver, removing the need for an iterative solution."
    ]
}